#!/bin/bash
#SBATCH --job-name=RADNLP
#SBATCH --partition=normal
#SBATCH --nodes=1
#SBATCH --output=/mnt/beegfs/lmolino/PycharmProjects/RADNLP/slurm/%A.out
#SBATCH --ntasks=1
#SBATCH --mem=32G
#SBATCH --gres=gpu:tesla:1
##SBATCH --gres=gpu:rtx:1
##SBATCH --gres=gpu:tesla:1
##SBATCH --gres=gpu:tesla:1
##SBATCH --gres=gpu:1
##SBATCH --gres=gpu:1
##SBATCH --gres=gpu:ampere:1

# (Opcional) Limpieza de m贸dulos cargados previamente
module purge

# (Opcional) Carga de m贸dulos software,usualmente cuda y cudnn
spack load miniconda3
spack load cuda@12.1

# (Opcional) Activaci贸n de entorno virtual de Conda
source activate foro

# Ejecuci贸n del primer paso
# echo python /mnt/beegfs/lmolino/PycharmProjects/${1}/run.py
# srun python /mnt/beegfs/lmolino/PycharmProjects/RADNLP/inference.py
srun python /mnt/beegfs/lmolino/PycharmProjects/RADNLP/train.py
# srun torchrun --nproc_per_node=4 /mnt/beegfs/lmolino/PycharmProjects/${1}/run.py
# srun python -m --num_processes=4 /mnt/beegfs/lmolino/PycharmProjects/${1}/run.py